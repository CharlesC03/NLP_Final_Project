{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772e63c4",
   "metadata": {},
   "source": [
    "# Preparing Data for Distallation\n",
    "\n",
    "Charles Ciampa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e179f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable\n",
    "import warnings\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6f05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceciampa/code/NLP_Final_Project/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'notebook_login': pass new_session=False as keyword args. From version 1.0 passing these as positional arguments will result in an error,\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8ecd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFCacheInfo(size_on_disk=32407506372, repos=frozenset({CachedRepoInfo(repo_id='meta-llama/Llama-3.1-8B', repo_type='model', repo_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B'), size_on_disk=16069717568, nb_files=10, revisions=frozenset({CachedRevisionInfo(commit_hash='d04e592bb4f6aa9cfee91e2e20afa771667e1d4b', snapshot_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b'), size_on_disk=16069717568, files=frozenset({CachedFileInfo(file_name='model-00004-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/model-00004-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d'), size_on_disk=1168138808, blob_last_accessed=1763091693.5002193, blob_last_modified=1763075071.8164258), CachedFileInfo(file_name='model-00001-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/model-00001-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b'), size_on_disk=4976698672, blob_last_accessed=1763075150.9998145, blob_last_modified=1763075150.7147567), CachedFileInfo(file_name='tokenizer_config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/tokenizer_config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/cb9ec25536e44d86778b10509d3e5bdca459a5cf'), size_on_disk=50500, blob_last_accessed=1763075026.8944545, blob_last_modified=1763075026.0800805), CachedFileInfo(file_name='model.safetensors.index.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/model.safetensors.index.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/0fd8120f1c6acddc268ebc2583058efaf699a771'), size_on_disk=23950, blob_last_accessed=1763075180.988573, blob_last_modified=1763075027.749547), CachedFileInfo(file_name='model-00003-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/model-00003-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383'), size_on_disk=4915916176, blob_last_accessed=1763091691.498641, blob_last_modified=1763075146.5609381), CachedFileInfo(file_name='model-00002-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/model-00002-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0'), size_on_disk=4999802720, blob_last_accessed=1763080956.0276797, blob_last_modified=1763075150.8878274), CachedFileInfo(file_name='special_tokens_map.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/special_tokens_map.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/d8cd5076496dbe4be2320312abc10adc43097b81'), size_on_disk=73, blob_last_accessed=1763075026.7010405, blob_last_modified=1763075026.782478), CachedFileInfo(file_name='config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/cccf055d6f8f210387a248c91dc40e0c7a4bafab'), size_on_disk=826, blob_last_accessed=1763075180.9273612, blob_last_modified=1763075027.281282), CachedFileInfo(file_name='generation_config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/generation_config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/fc9506438b7b55383dc04c0816561442324846c3'), size_on_disk=185, blob_last_accessed=1763091499.9824295, blob_last_modified=1763091464.6140099), CachedFileInfo(file_name='tokenizer.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b/tokenizer.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B/blobs/f916e71031fa08f3c6ef1680a590c15b52d3cdd9'), size_on_disk=9085658, blob_last_accessed=1763075026.904634, blob_last_modified=1763075026.497447)}), refs=frozenset({'main'}), last_modified=1763091464.6140099)}), last_accessed=1763091693.5002193, last_modified=1763091464.6140099), CachedRepoInfo(repo_id='google/pegasus-xsum', repo_type='model', repo_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--google--pegasus-xsum'), size_on_disk=1392, nb_files=1, revisions=frozenset({CachedRevisionInfo(commit_hash='8d8ffc158a3bee9fbb03afacdfc347c823c5ec8b', snapshot_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--google--pegasus-xsum/snapshots/8d8ffc158a3bee9fbb03afacdfc347c823c5ec8b'), size_on_disk=1392, files=frozenset({CachedFileInfo(file_name='config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--google--pegasus-xsum/snapshots/8d8ffc158a3bee9fbb03afacdfc347c823c5ec8b/config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--google--pegasus-xsum/blobs/187e4581ab878876269409ed3066a0c45b421d12'), size_on_disk=1392, blob_last_accessed=1762911889.0277314, blob_last_modified=1762911846.5530903)}), refs=frozenset({'main'}), last_modified=1762911846.5530903)}), last_accessed=1762911889.0277314, last_modified=1762911846.5530903), CachedRepoInfo(repo_id='meta-llama/Meta-Llama-3.1-8B-Instruct', repo_type='model', repo_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct'), size_on_disk=16069722669, nb_files=10, revisions=frozenset({CachedRevisionInfo(commit_hash='0e9e39f249a16976918f6564b8830bc894c89659', snapshot_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659'), size_on_disk=16069722669, files=frozenset({CachedFileInfo(file_name='model-00003-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model-00003-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/fc1cdddd6bfa91128d6e94ee73d0ce62bfcdb7af29e978ddcab30c66ae9ea7fa'), size_on_disk=4915916176, blob_last_accessed=1763932411.0501504, blob_last_modified=1763094406.1886187), CachedFileInfo(file_name='generation_config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/generation_config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/cc7276afd599de091142c6ed3005faf8a74aa257'), size_on_disk=184, blob_last_accessed=1763932415.5678933, blob_last_modified=1763094412.2045398), CachedFileInfo(file_name='model-00004-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model-00004-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/92ecfe1a2414458b4821ac8c13cf8cb70aed66b5eea8dc5ad9eeb4ff309d6d7b'), size_on_disk=1168138808, blob_last_accessed=1763932414.586664, blob_last_modified=1763094328.6645076), CachedFileInfo(file_name='special_tokens_map.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/special_tokens_map.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/02ee80b6196926a5ad790a004d9efd6ab1ba6542'), size_on_disk=296, blob_last_accessed=1763094180.3732944, blob_last_modified=1763094180.433744), CachedFileInfo(file_name='config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/0bb6fd75b3ad2fe988565929f329945262c2814e'), size_on_disk=855, blob_last_accessed=1763932400.6974502, blob_last_modified=1763094181.0281768), CachedFileInfo(file_name='tokenizer.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/5cc5f00a5b203e90a27a3bd60d1ec393b07971e8'), size_on_disk=9085657, blob_last_accessed=1763932400.3703275, blob_last_modified=1763094180.0307467), CachedFileInfo(file_name='model-00001-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model-00001-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/2b1879f356aed350030bb40eb45ad362c89d9891096f79a3ab323d3ba5607668'), size_on_disk=4976698672, blob_last_accessed=1763932401.7401533, blob_last_modified=1763094406.9482195), CachedFileInfo(file_name='model-00002-of-00004.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model-00002-of-00004.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/09d433f650646834a83c580877bd60c6d1f88f7755305c12576b5c7058f9af15'), size_on_disk=4999802720, blob_last_accessed=1763932406.6977615, blob_last_modified=1763094407.8394845), CachedFileInfo(file_name='model.safetensors.index.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/model.safetensors.index.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/0fd8120f1c6acddc268ebc2583058efaf699a771'), size_on_disk=23950, blob_last_accessed=1763932400.9223468, blob_last_modified=1763094181.320526), CachedFileInfo(file_name='tokenizer_config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer_config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/blobs/db88166e2bc4c799fd5d1ae643b75e84d03ee70e'), size_on_disk=55351, blob_last_accessed=1763932400.2681017, blob_last_modified=1763094179.4065166)}), refs=frozenset({'main'}), last_modified=1763094412.2045398)}), last_accessed=1763932415.5678933, last_modified=1763094412.2045398), CachedRepoInfo(repo_id='distilbert/distilbert-base-uncased-finetuned-sst-2-english', repo_type='model', repo_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english'), size_on_disk=268064743, nb_files=4, revisions=frozenset({CachedRevisionInfo(commit_hash='714eb0fa89d2f80546fda750413ed43d93601a13', snapshot_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13'), size_on_disk=268064743, files=frozenset({CachedFileInfo(file_name='config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/blobs/b57fe5dfcb8ec3f9bab35ed427c3434e3c7dd1ba'), size_on_disk=629, blob_last_accessed=1763073135.9585092, blob_last_modified=1763073135.938044), CachedFileInfo(file_name='tokenizer_config.json', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/tokenizer_config.json'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/blobs/3ed34255a7cb8e6706a8bb21993836e99e7b959f'), size_on_disk=48, blob_last_accessed=1763073139.2726648, blob_last_modified=1763073138.793176), CachedFileInfo(file_name='model.safetensors', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/model.safetensors'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/blobs/7c3919835e442510166d267fe7cbe847e0c51cd26d9ba07b89a57b952b49b8aa'), size_on_disk=267832558, blob_last_accessed=1763073138.6809552, blob_last_modified=1763073138.6401477), CachedFileInfo(file_name='vocab.txt', file_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/vocab.txt'), blob_path=PosixPath('/home/ceciampa/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938'), size_on_disk=231508, blob_last_accessed=1763073139.2726648, blob_last_modified=1763073138.987012)}), refs=frozenset({'714eb0f'}), last_modified=1763073138.987012)}), last_accessed=1763073139.2726648, last_modified=1763073138.987012)}), warnings=[CorruptedCacheException('Repo path is not a directory: /home/ceciampa/.cache/huggingface/hub/version.txt')])\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "print(scan_cache_dir())\n",
    "# delete_strategy = scan_cache_dir().delete_revisions(\n",
    "#     \"8d8ffc158a3bee9fbb03afacdfc347c823c5ec8b\"\n",
    "# )\n",
    "\n",
    "# print(\"Will free \" + delete_strategy.expected_freed_size_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ef6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilModelData:\n",
    "    \"\"\" Class will load data from a tokenizer, model, and a dataset. Also a prompt and labels will be provided.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize the variables\n",
    "        self._train_df = None\n",
    "        self._test_df = None\n",
    "        self._labels = None\n",
    "        self._reversed_labels = None\n",
    "        self._prompt: Callable | None = None\n",
    "        self._num_examples: int = 0\n",
    "        self._model: AutoModelForCausalLM = None\n",
    "        self._tokenizer: AutoTokenizer = None\n",
    "    \n",
    "    def set_labels(self, labels: Dict[int, str]):\n",
    "        \"\"\"Provided a dictionary of labels it will se the labels. The keys are the integer labels in the dataset and the values of the dictionary are the labels for the prompt into the models.\n",
    "\n",
    "        Args:\n",
    "            labels (Dict[int, str]): The labels to be saved\n",
    "\n",
    "        Raises:\n",
    "            ValueError: A dictionary must be provided as input otherwise an error will be risen.\n",
    "            ValueError: If not all the keys are integers it will cause issues.\n",
    "            ValueError: If not all the values are strings it will raise an error.\n",
    "        \"\"\"\n",
    "        if self._train_df is None or self._test_df is None:\n",
    "            raise ValueError(\"The train and test dataframes have not be set yet. You must set to ensure that each of the labels in the dataframe have been set.\")\n",
    "        if not isinstance(labels, dict):\n",
    "            raise ValueError(\"Labels must be a dictionary\")\n",
    "        if not all(isinstance(k, int) for k in labels.keys()):\n",
    "            raise ValueError(\"Label keys must be integers\")\n",
    "        if not all(isinstance(v, str) for v in labels.values()):\n",
    "            raise ValueError(\"Label values must be strings\")\n",
    "        label_keys = set(labels.keys())\n",
    "        train_df_labels = set(self._train_df['label'].unique())\n",
    "        test_df_labels = set(self._test_df[\"label\"].unique())\n",
    "        if not train_df_labels.issubset(label_keys) or not test_df_labels.issubset(label_keys):\n",
    "            raise ValueError(f\"The provided labels are missing assigned string values for the following values: {', '.join(train_df_labels.difference(label_keys).union(test_df_labels.difference(label_keys)))}.\")\n",
    "        self._labels = labels\n",
    "        self._reversed_labels = {v: k for k, v in self._labels.items()}\n",
    "    \n",
    "    def set_num_examples_in_prompt(self, num: int = 0):\n",
    "        \"\"\"Provided an integer it will set the number of examples in the prompt.\n",
    "\n",
    "        Args:\n",
    "            num (int): The number of examples to be saved.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: An integer must be provided.\n",
    "        \"\"\"\n",
    "        if not isinstance(num, int):\n",
    "            raise ValueError(\"An integer must be provided\")\n",
    "        self._num_examples = num\n",
    "    \n",
    "    def set_prompt(self, prompt_func: Callable[[str, dict, pd.DataFrame], str]):\n",
    "        # Prompt function takes in as such f(string to label, label options, example dataframe) -> prompt string\n",
    "        self._prompt = prompt_func\n",
    "\n",
    "    def set_model(self, model_name: str, bnb_config: None | BitsAndBytesConfig = None):\n",
    "        if not isinstance(model_name, str):\n",
    "            raise ValueError(\"A model name must be provided as a string\")\n",
    "        \n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "        self._model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        print(self._model.device)\n",
    "\n",
    "    def reset_datasets_and_labels(self):\n",
    "        self._labels = None\n",
    "        self._train_df = None\n",
    "        self._test_df = None\n",
    "    \n",
    "    def set_datasets_from_path(\n",
    "        self,\n",
    "        train_path: str,\n",
    "        test_path: str,\n",
    "        rename_columns: Dict[str, str] = {},\n",
    "        create_columns: None | Callable[[pd.DataFrame], pd.DataFrame] = None,\n",
    "        ignore_common_text_thresh: float = 0,\n",
    "    ):\n",
    "        # Loads the data\n",
    "        try:\n",
    "            train_temp = pd.read_parquet(train_path)\n",
    "            test_temp = pd.read_parquet(test_path)\n",
    "            # Renames the columns if provided any renames. This is there to help you make sure there is a text and label column as these will be used in this code\n",
    "            train_temp.rename(columns=rename_columns, inplace=True)\n",
    "            test_temp.rename(columns=rename_columns, inplace=True)\n",
    "            # Runs a provided function which modifies the data to ensure that there are columns text and label, and their values are appropriet.\n",
    "            if create_columns is not None:\n",
    "                train_temp = create_columns(train_temp)\n",
    "                test_temp = create_columns(test_temp)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        # This is where it actually sets the data. At this point no errors should have occured so its safe to finally set the values. The last checks will be here.\n",
    "        self.set_datasets(\n",
    "            train_temp.copy(),\n",
    "            test_temp.copy(),\n",
    "            ignore_common_text_thresh=ignore_common_text_thresh,\n",
    "        )\n",
    "    \n",
    "\n",
    "    def set_datasets(self, train_df: pd.DataFrame, test_df: pd.DataFrame, ignore_common_text_thresh: float = 0):\n",
    "        \"\"\"Sets the train and test datasets.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): The training dataframe.\n",
    "            test_df (pd.DataFrame): The testing dataframe.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Both inputs must be pandas DataFrames.\n",
    "            ValueError: Train DataFrame must have 'text' and 'label' columns.\n",
    "            ValueError: Test DataFrame must have 'text' and 'label' columns.\n",
    "            ValueError: Train DataFrame 'label' column must be of integer type.\n",
    "            ValueError: Test DataFrame 'label' column must be of integer type.\n",
    "            ValueError: Train DataFrame 'text' column must be of string type.\n",
    "            ValueError: Test DataFrame 'text' column must be of string type.\n",
    "            ValueError: Train and Test DataFrames share common text entries. Data leakage detected.\n",
    "        \"\"\"\n",
    "        # Ensures that both of the inputs are DataFrames\n",
    "        if not isinstance(train_df, pd.DataFrame) or not isinstance(test_df, pd.DataFrame):\n",
    "            raise ValueError(\"Both inputs must be pandas DataFrames.\")\n",
    "        \n",
    "        # Checks that there is a labels and text column\n",
    "        if \"text\" not in train_df.columns or \"label\" not in train_df.columns:\n",
    "            raise ValueError(\"Train DataFrame must have 'text' and 'label' columns.\")\n",
    "        if \"text\" not in test_df.columns or \"label\" not in test_df.columns:\n",
    "            raise ValueError(\"Test DataFrame must have 'text' and 'label' columns.\")\n",
    "        \n",
    "        # Ensure that the labels are of the integer type\n",
    "        if not pd.api.types.is_integer_dtype(train_df[\"label\"]):\n",
    "            raise ValueError(\"Train DataFrame 'label' column must be of integer type.\")\n",
    "        if not pd.api.types.is_integer_dtype(test_df[\"label\"]):\n",
    "            raise ValueError(\"Test DataFrame 'label' column must be of integer type.\")\n",
    "        \n",
    "        # Ensure that the text columns are a string value\n",
    "        if not pd.api.types.is_string_dtype(train_df[\"text\"]):\n",
    "            raise ValueError(\"Train DataFrame 'text' column must be of string type\")\n",
    "        if not pd.api.types.is_string_dtype(test_df[\"text\"]):\n",
    "            raise ValueError(\"Test DataFrame 'text' column must be of string type\")\n",
    "        \n",
    "        # Check for overlapping data between train and test sets based on the 'text' column\n",
    "        common_texts = set(train_df[\"text\"]).intersection(set(test_df[\"text\"]))\n",
    "        if common_texts:\n",
    "            perc = len(common_texts) / len(test_df) \n",
    "            err = f\"Data leakage detected! Train and Test DataFrames share {len(common_texts)} ({perc:.2%} of testing dataset) common text entries.\"\n",
    "            if perc > ignore_common_text_thresh:\n",
    "                raise ValueError(err)\n",
    "            else:\n",
    "                warnings.warn(err)\n",
    "        self._train_df = train_df\n",
    "        self._test_df = test_df\n",
    "\n",
    "    def distil_labels(self):\n",
    "        if self._labels is None:\n",
    "            raise ValueError(\"Labels must be set.\")\n",
    "        if self._train_df is None or self._test_df is None:\n",
    "            raise ValueError(\"Datasets must be set.\")\n",
    "        if self._model is None or self._tokenizer is None:\n",
    "            raise ValueError(\"Model and Tokenizer must be set\")\n",
    "        if self._prompt is None:\n",
    "            raise ValueError(\"Prompt must be set.\")\n",
    "        if self._model is None or self._tokenizer is None:\n",
    "            raise ValueError(\"Model and Tokenizer have not been set yet.\")\n",
    "        \n",
    "        train_examples = {k: [] for k in self._labels.keys()}\n",
    "        with torch.inference_mode():\n",
    "            for i, row in tqdm(self._train_df.iterrows(), total=len(self._train_df), desc=\"Getting Probability of Labels\"):\n",
    "                # Create the prompt\n",
    "                prompt = self._prompt(\n",
    "                    row[\"text\"], self._labels, self._train_df.drop(i).sample(self._num_examples)\n",
    "                )\n",
    "                # Get the prompt encoding\n",
    "                model_inputs = self._tokenizer(prompt, return_tensors=\"pt\").to(\n",
    "                    self._model.device\n",
    "                )\n",
    "                # Input into the model and get the output\n",
    "                model_outputs = self._model(**model_inputs)\n",
    "                # Get the last token output\n",
    "                next_token_logits = model_outputs.logits[:, -1, :]\n",
    "                # Get the probabilities of the values\n",
    "                probs = F.softmax(next_token_logits, dim=-1)[0]\n",
    "                # Iterate through the labels and get the probability of it\n",
    "                label_probs = {}\n",
    "                for label in self._labels.values():\n",
    "                    # For simplicity, use first token probability\n",
    "                    label_tokens = self._tokenizer.encode(f\" {label}\", add_special_tokens=False)\n",
    "                    token_id = label_tokens[0]\n",
    "                    prob = probs[token_id].item()\n",
    "                    label_probs[label] = prob\n",
    "                # Normalize the probabilities of the values\n",
    "                total = sum(label_probs.values())\n",
    "                for k, v in label_probs.items():\n",
    "                    train_examples[self._reversed_labels[k]].append(v / total)\n",
    "        for k, v in train_examples.items():\n",
    "            self._train_df[f'label_{k}'] = v\n",
    "    def folder_export(self, path: str):\n",
    "        if self._test_df  is None or self._train_df is None:\n",
    "            raise ValueError(\"The datasets have not been set.\")\n",
    "        self._train_df.to_csv(f\"{path}train.csv\", index=False)\n",
    "        self._test_df.to_csv(f\"{path}test.csv\", index=False)\n",
    "    \n",
    "    def export_files(self, train_path: str, test_path: str):\n",
    "        if self._test_df is None or self._train_df is None:\n",
    "            raise ValueError(\"The datasets have not been set.\")\n",
    "        self._train_df.to_csv(train_path, index=False)\n",
    "        self._test_df.to_csv(test_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e688d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_217897/2103688644.py:157: UserWarning: Data leakage detected! Train and Test DataFrames share 123 (0.49% of testing dataset) common text entries.\n",
      "  warnings.warn(err)\n"
     ]
    }
   ],
   "source": [
    "model_distallation = DistilModelData()\n",
    "\n",
    "# # \"hf://datasets/stanfordnlp/imdb/\" + splits[\"train\"])\n",
    "# splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'test': 'plain_text/test-00000-of-00001.parquet', 'unsupervised': 'plain_text/unsupervised-00000-of-00001.parquet'}\n",
    "model_distallation.set_datasets_from_path(\n",
    "    train_path=\"hf://datasets/stanfordnlp/imdb/plain_text/train-00000-of-00001.parquet\",\n",
    "    test_path=\"hf://datasets/stanfordnlp/imdb/plain_text/test-00000-of-00001.parquet\",\n",
    "    ignore_common_text_thresh=0.01\n",
    ")\n",
    "\n",
    "model_distallation.set_labels({0: \"Negative\", 1: \"Positive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a0d00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fa57f7adab4a2490b5a38677b70e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_distallation.set_model(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e646851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_distallation.set_prompt(\n",
    "    lambda ex,\n",
    "    labels,\n",
    "    _: f\"\"\"Classify the sentiment as {\", \".join(list(labels.values())[:-1])}, or {list(labels.values())[-1]}.\n",
    "\n",
    "Text: {ex}\n",
    "Sentiment:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f007004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c492b9c30db14b999001ad960eda78b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting Probability of Labels:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_distallation.distil_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fb5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_distallation.folder_export(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a084fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>0.979046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978229</td>\n",
       "      <td>0.021771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988581</td>\n",
       "      <td>0.011419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983598</td>\n",
       "      <td>0.016402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>0.007873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936263</td>\n",
       "      <td>0.063737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.997178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.998858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078626</td>\n",
       "      <td>0.921374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.976307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label   label_0  \\\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0  0.020954   \n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0  0.978229   \n",
       "2      If only to avoid making this type of film in t...      0  0.988581   \n",
       "3      This film was probably inspired by Godard's Ma...      0  0.983598   \n",
       "4      Oh, brother...after hearing about this ridicul...      0  0.992127   \n",
       "...                                                  ...    ...       ...   \n",
       "24995  A hit at the time but now better categorised a...      1  0.936263   \n",
       "24996  I love this movie like no other. Another time ...      1  0.002822   \n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1  0.001142   \n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1  0.078626   \n",
       "24999  The story centers around Barry McKenzie who mu...      1  0.023693   \n",
       "\n",
       "        label_1  \n",
       "0      0.979046  \n",
       "1      0.021771  \n",
       "2      0.011419  \n",
       "3      0.016402  \n",
       "4      0.007873  \n",
       "...         ...  \n",
       "24995  0.063737  \n",
       "24996  0.997178  \n",
       "24997  0.998858  \n",
       "24998  0.921374  \n",
       "24999  0.976307  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_distallation._train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
